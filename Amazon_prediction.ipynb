{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Amazon_prediction.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "OATeWGLwhn6o",
        "colab_type": "code",
        "outputId": "3f84f18d-1f3b-46bd-8f9c-18003781c29f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 672
        }
      },
      "source": [
        "!pip install quandl\n",
        "import quandl\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting quandl\n",
            "  Downloading https://files.pythonhosted.org/packages/12/64/6314547cb01fa75697ddba6d6d43a9f1d023c1730ffc6abf3db7a0c89222/Quandl-3.4.8-py2.py3-none-any.whl\n",
            "Collecting ndg-httpsclient\n",
            "  Downloading https://files.pythonhosted.org/packages/fb/67/c2f508c00ed2a6911541494504b7cac16fe0b0473912568df65fd1801132/ndg_httpsclient-0.5.1-py3-none-any.whl\n",
            "Collecting inflection>=0.3.1\n",
            "  Downloading https://files.pythonhosted.org/packages/d5/35/a6eb45b4e2356fe688b21570864d4aa0d0a880ce387defe9c589112077f8/inflection-0.3.1.tar.gz\n",
            "Requirement already satisfied: numpy>=1.8 in /usr/local/lib/python3.6/dist-packages (from quandl) (1.17.4)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from quandl) (2.6.1)\n",
            "Collecting pyOpenSSL\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/de/f8342b68fa9e981d348039954657bdf681b2ab93de27443be51865ffa310/pyOpenSSL-19.1.0-py2.py3-none-any.whl (53kB)\n",
            "\r\u001b[K     |██████                          | 10kB 14.8MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 20kB 21.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 30kB 26.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 40kB 30.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 51kB 34.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 7.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=0.14 in /usr/local/lib/python3.6/dist-packages (from quandl) (0.25.3)\n",
            "Requirement already satisfied: pyasn1 in /usr/local/lib/python3.6/dist-packages (from quandl) (0.4.7)\n",
            "Collecting more-itertools<=5.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a4/a6/42f17d065bda1fac255db13afc94c93dbfb64393eae37c749b4cb0752fc7/more_itertools-5.0.0-py3-none-any.whl (52kB)\n",
            "\r\u001b[K     |██████▎                         | 10kB 15.0MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 20kB 20.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 30kB 25.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 40kB 28.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 51kB 30.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 6.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.7.0 in /usr/local/lib/python3.6/dist-packages (from quandl) (2.21.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from quandl) (1.12.0)\n",
            "Collecting cryptography>=2.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/9a/7cece52c46546e214e10811b36b2da52ce1ea7fa203203a629b8dfadad53/cryptography-2.8-cp34-abi3-manylinux2010_x86_64.whl (2.3MB)\n",
            "\r\u001b[K     |▏                               | 10kB 16.8MB/s eta 0:00:01\r\u001b[K     |▎                               | 20kB 24.7MB/s eta 0:00:01\r\u001b[K     |▍                               | 30kB 31.5MB/s eta 0:00:01\r\u001b[K     |▋                               | 40kB 36.0MB/s eta 0:00:01\r\u001b[K     |▊                               | 51kB 38.6MB/s eta 0:00:01\r\u001b[K     |▉                               | 61kB 41.5MB/s eta 0:00:01\r\u001b[K     |█                               | 71kB 6.2MB/s eta 0:00:01\r\u001b[K     |█▏                              | 81kB 6.8MB/s eta 0:00:01\r\u001b[K     |█▎                              | 92kB 7.5MB/s eta 0:00:01\r\u001b[K     |█▍                              | 102kB 8.3MB/s eta 0:00:01\r\u001b[K     |█▋                              | 112kB 8.3MB/s eta 0:00:01\r\u001b[K     |█▊                              | 122kB 8.3MB/s eta 0:00:01\r\u001b[K     |█▉                              | 133kB 8.3MB/s eta 0:00:01\r\u001b[K     |██                              | 143kB 8.3MB/s eta 0:00:01\r\u001b[K     |██▏                             | 153kB 8.3MB/s eta 0:00:01\r\u001b[K     |██▎                             | 163kB 8.3MB/s eta 0:00:01\r\u001b[K     |██▌                             | 174kB 8.3MB/s eta 0:00:01\r\u001b[K     |██▋                             | 184kB 8.3MB/s eta 0:00:01\r\u001b[K     |██▊                             | 194kB 8.3MB/s eta 0:00:01\r\u001b[K     |██▉                             | 204kB 8.3MB/s eta 0:00:01\r\u001b[K     |███                             | 215kB 8.3MB/s eta 0:00:01\r\u001b[K     |███▏                            | 225kB 8.3MB/s eta 0:00:01\r\u001b[K     |███▎                            | 235kB 8.3MB/s eta 0:00:01\r\u001b[K     |███▌                            | 245kB 8.3MB/s eta 0:00:01\r\u001b[K     |███▋                            | 256kB 8.3MB/s eta 0:00:01\r\u001b[K     |███▊                            | 266kB 8.3MB/s eta 0:00:01\r\u001b[K     |████                            | 276kB 8.3MB/s eta 0:00:01\r\u001b[K     |████                            | 286kB 8.3MB/s eta 0:00:01\r\u001b[K     |████▏                           | 296kB 8.3MB/s eta 0:00:01\r\u001b[K     |████▎                           | 307kB 8.3MB/s eta 0:00:01\r\u001b[K     |████▌                           | 317kB 8.3MB/s eta 0:00:01\r\u001b[K     |████▋                           | 327kB 8.3MB/s eta 0:00:01\r\u001b[K     |████▊                           | 337kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████                           | 348kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████                           | 358kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 368kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 378kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 389kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 399kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 409kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████                          | 419kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████                          | 430kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 440kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 450kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 460kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 471kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 481kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████                         | 491kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████                         | 501kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 512kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 522kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 532kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 542kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 552kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████                        | 563kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████                        | 573kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 583kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 593kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 604kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 614kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 624kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████                       | 634kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████                       | 645kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 655kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 665kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 675kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 686kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 696kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████                      | 706kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████                      | 716kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 727kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 737kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 747kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 757kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 768kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████                     | 778kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████                     | 788kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 798kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 808kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 819kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 829kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 839kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████                    | 849kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████                    | 860kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 870kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 880kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 890kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 901kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 911kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 921kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 931kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 942kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 952kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 962kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 972kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 983kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 993kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 1.0MB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 1.0MB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 1.0MB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 1.0MB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 1.0MB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 1.1MB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 1.1MB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 1.1MB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 1.1MB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 1.1MB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 1.1MB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 1.1MB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 1.1MB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████                | 1.1MB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 1.1MB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 1.2MB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 1.2MB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 1.2MB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 1.2MB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 1.2MB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 1.2MB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 1.2MB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 1.2MB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 1.2MB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 1.2MB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 1.3MB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 1.3MB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 1.3MB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 1.3MB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 1.3MB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 1.3MB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 1.3MB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 1.3MB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 1.3MB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 1.4MB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 1.4MB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 1.4MB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 1.4MB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 1.4MB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 1.4MB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 1.4MB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.4MB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 1.4MB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 1.4MB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 1.5MB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 1.5MB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 1.5MB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 1.5MB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.5MB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 1.5MB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 1.5MB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 1.5MB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 1.5MB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 1.5MB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.6MB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.6MB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 1.6MB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 1.6MB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 1.6MB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 1.6MB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 1.6MB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.6MB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.6MB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 1.6MB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 1.7MB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 1.7MB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 1.7MB 47kB/s eta 0:00:13\r\u001b[K     |███████████████████████▊        | 1.7MB 47kB/s eta 0:00:13\r\u001b[K     |████████████████████████        | 1.7MB 47kB/s eta 0:00:13\r\u001b[K     |████████████████████████        | 1.7MB 47kB/s eta 0:00:12\r\u001b[K     |████████████████████████▏       | 1.7MB 47kB/s eta 0:00:12\r\u001b[K     |████████████████████████▍       | 1.7MB 47kB/s eta 0:00:12\r\u001b[K     |████████████████████████▌       | 1.7MB 47kB/s eta 0:00:12\r\u001b[K     |████████████████████████▋       | 1.8MB 47kB/s eta 0:00:11\r\u001b[K     |████████████████████████▊       | 1.8MB 47kB/s eta 0:00:11\r\u001b[K     |█████████████████████████       | 1.8MB 47kB/s eta 0:00:11\r\u001b[K     |█████████████████████████       | 1.8MB 47kB/s eta 0:00:11\r\u001b[K     |█████████████████████████▏      | 1.8MB 47kB/s eta 0:00:11\r\u001b[K     |█████████████████████████▍      | 1.8MB 47kB/s eta 0:00:10\r\u001b[K     |█████████████████████████▌      | 1.8MB 47kB/s eta 0:00:10\r\u001b[K     |█████████████████████████▋      | 1.8MB 47kB/s eta 0:00:10\r\u001b[K     |█████████████████████████▉      | 1.8MB 47kB/s eta 0:00:10\r\u001b[K     |██████████████████████████      | 1.8MB 47kB/s eta 0:00:10\r\u001b[K     |██████████████████████████      | 1.9MB 47kB/s eta 0:00:09\r\u001b[K     |██████████████████████████▏     | 1.9MB 47kB/s eta 0:00:09\r\u001b[K     |██████████████████████████▍     | 1.9MB 47kB/s eta 0:00:09\r\u001b[K     |██████████████████████████▌     | 1.9MB 47kB/s eta 0:00:09\r\u001b[K     |██████████████████████████▋     | 1.9MB 47kB/s eta 0:00:08\r\u001b[K     |██████████████████████████▉     | 1.9MB 47kB/s eta 0:00:08\r\u001b[K     |███████████████████████████     | 1.9MB 47kB/s eta 0:00:08\r\u001b[K     |███████████████████████████     | 1.9MB 47kB/s eta 0:00:08\r\u001b[K     |███████████████████████████▎    | 1.9MB 47kB/s eta 0:00:08\r\u001b[K     |███████████████████████████▍    | 1.9MB 47kB/s eta 0:00:07\r\u001b[K     |███████████████████████████▌    | 2.0MB 47kB/s eta 0:00:07\r\u001b[K     |███████████████████████████▋    | 2.0MB 47kB/s eta 0:00:07\r\u001b[K     |███████████████████████████▉    | 2.0MB 47kB/s eta 0:00:07\r\u001b[K     |████████████████████████████    | 2.0MB 47kB/s eta 0:00:07\r\u001b[K     |████████████████████████████    | 2.0MB 47kB/s eta 0:00:06\r\u001b[K     |████████████████████████████▎   | 2.0MB 47kB/s eta 0:00:06\r\u001b[K     |████████████████████████████▍   | 2.0MB 47kB/s eta 0:00:06\r\u001b[K     |████████████████████████████▌   | 2.0MB 47kB/s eta 0:00:06\r\u001b[K     |████████████████████████████▋   | 2.0MB 47kB/s eta 0:00:05\r\u001b[K     |████████████████████████████▉   | 2.0MB 47kB/s eta 0:00:05\r\u001b[K     |█████████████████████████████   | 2.1MB 47kB/s eta 0:00:05\r\u001b[K     |█████████████████████████████   | 2.1MB 47kB/s eta 0:00:05\r\u001b[K     |█████████████████████████████▎  | 2.1MB 47kB/s eta 0:00:05\r\u001b[K     |█████████████████████████████▍  | 2.1MB 47kB/s eta 0:00:04\r\u001b[K     |█████████████████████████████▌  | 2.1MB 47kB/s eta 0:00:04\r\u001b[K     |█████████████████████████████▊  | 2.1MB 47kB/s eta 0:00:04\r\u001b[K     |█████████████████████████████▉  | 2.1MB 47kB/s eta 0:00:04\r\u001b[K     |██████████████████████████████  | 2.1MB 47kB/s eta 0:00:04\r\u001b[K     |██████████████████████████████  | 2.1MB 47kB/s eta 0:00:03\r\u001b[K     |██████████████████████████████▎ | 2.2MB 47kB/s eta 0:00:03\r\u001b[K     |██████████████████████████████▍ | 2.2MB 47kB/s eta 0:00:03\r\u001b[K     |██████████████████████████████▌ | 2.2MB 47kB/s eta 0:00:03\r\u001b[K     |██████████████████████████████▊ | 2.2MB 47kB/s eta 0:00:02\r\u001b[K     |██████████████████████████████▉ | 2.2MB 47kB/s eta 0:00:02\r\u001b[K     |███████████████████████████████ | 2.2MB 47kB/s eta 0:00:02\r\u001b[K     |███████████████████████████████▏| 2.2MB 47kB/s eta 0:00:02\r\u001b[K     |███████████████████████████████▎| 2.2MB 47kB/s eta 0:00:02\r\u001b[K     |███████████████████████████████▍| 2.2MB 47kB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 2.2MB 47kB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 2.3MB 47kB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 2.3MB 47kB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 2.3MB 47kB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 2.3MB 47kB/s \n",
            "\u001b[?25hRequirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.14->quandl) (2018.9)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.7.0->quandl) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.7.0->quandl) (2019.9.11)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.7.0->quandl) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.7.0->quandl) (1.24.3)\n",
            "Requirement already satisfied: cffi!=1.11.3,>=1.8 in /usr/local/lib/python3.6/dist-packages (from cryptography>=2.8->pyOpenSSL->quandl) (1.13.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi!=1.11.3,>=1.8->cryptography>=2.8->pyOpenSSL->quandl) (2.19)\n",
            "Building wheels for collected packages: inflection\n",
            "  Building wheel for inflection (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for inflection: filename=inflection-0.3.1-cp36-none-any.whl size=6076 sha256=bd95d0e8b7934c8339138d81a292c7b9b336a5e1b3b2be9b7958c48ae7327be4\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/5a/d3/6fc3bf6516d2a3eb7e18f9f28b472110b59325f3f258fe9211\n",
            "Successfully built inflection\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: cryptography, pyOpenSSL, ndg-httpsclient, inflection, more-itertools, quandl\n",
            "  Found existing installation: more-itertools 7.2.0\n",
            "    Uninstalling more-itertools-7.2.0:\n",
            "      Successfully uninstalled more-itertools-7.2.0\n",
            "Successfully installed cryptography-2.8 inflection-0.3.1 more-itertools-5.0.0 ndg-httpsclient-0.5.1 pyOpenSSL-19.1.0 quandl-3.4.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "66k2z-kf50pp",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bX_UNQ9ph2Oq",
        "colab_type": "code",
        "outputId": "89e372ba-5f57-4581-e4f5-372edff84342",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 638
        }
      },
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/gdrive')\n",
        "#train=pd.read_csv('./gdrive/My Drive/AAPL.csv');\n",
        "from statistics import mean\n",
        "dict={}\n",
        "df = quandl.get(\"WIKI/AMZN\")\n",
        "train=df.copy()\n",
        "train=train.iloc[5224:5248,7:13]\n",
        "print(train)\n",
        "for i in train:\n",
        "  test=train[i]\n",
        "  x_train,x_test,y_train,y_test=train_test_split(train,test,test_size=0.3)\n",
        "  model=DecisionTreeRegressor()\n",
        "  model.fit(x_train,y_train)\n",
        "  predi=model.predict(x_test)\n",
        "  acc=model.score(x_test,y_test)\n",
        "  predict=mean(predi)\n",
        "  print(predict)\n",
        "  print('Accuracy is:',acc)\n",
        "  dict.update({i:predict})\n",
        "print(dict)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "            Adj. Open  Adj. High  Adj. Low  Adj. Close  Adj. Volume\n",
            "Date                                                               \n",
            "2018-02-22    1495.36    1502.54   1475.76     1484.76    4732555.0\n",
            "2018-02-23    1495.34    1500.00   1486.50     1500.00    4327008.0\n",
            "2018-02-26    1509.20    1522.84   1507.00     1521.95    4909053.0\n",
            "2018-02-27    1524.50    1526.78   1507.21     1511.98    4708378.0\n",
            "2018-02-28    1519.51    1528.70   1512.00     1512.45    4426580.0\n",
            "2018-03-01    1513.60    1518.49   1465.00     1493.45    6835230.0\n",
            "2018-03-02    1469.10    1501.05   1455.01     1500.25    6587564.0\n",
            "2018-03-05    1494.24    1525.38   1481.00     1523.61    5233934.0\n",
            "2018-03-06    1533.20    1542.13   1528.00     1537.64    4561718.0\n",
            "2018-03-07    1526.52    1545.90   1522.51     1545.00    4174123.0\n",
            "2018-03-08    1550.00    1554.88   1545.25     1551.86    3512528.0\n",
            "2018-03-09    1563.50    1578.94   1559.08     1578.89    4417059.0\n",
            "2018-03-12    1592.60    1605.33   1586.70     1598.39    5115886.0\n",
            "2018-03-13    1615.96    1617.54   1578.01     1588.18    6427066.0\n",
            "2018-03-14    1597.00    1606.44   1590.89     1591.00    4164395.0\n",
            "2018-03-15    1595.00    1596.91   1578.11     1582.32    4026744.0\n",
            "2018-03-16    1583.45    1589.44   1567.50     1571.68    5145054.0\n",
            "2018-03-19    1554.53    1561.66   1525.35     1544.93    6376619.0\n",
            "2018-03-20    1550.34    1587.00   1545.41     1586.51    4507049.0\n",
            "2018-03-21    1586.45    1590.00   1563.17     1581.86    4667291.0\n",
            "2018-03-22    1565.47    1573.85   1542.40     1544.10    6177737.0\n",
            "2018-03-23    1539.01    1549.02   1495.36     1495.56    7843966.0\n",
            "2018-03-26    1530.00    1556.99   1499.25     1555.86    5547618.0\n",
            "2018-03-27    1572.40    1575.96   1482.32     1497.05    6793279.0\n",
            "1538.00125\n",
            "Accuracy is: 0.8774732503117362\n",
            "1565.6075\n",
            "Accuracy is: 0.8158800713525436\n",
            "1502.78125\n",
            "Accuracy is: 0.8738752311719556\n",
            "1555.23\n",
            "Accuracy is: 0.865473537187637\n",
            "5309783.5\n",
            "Accuracy is: 0.7783161271275596\n",
            "{'Adj. Open': 1538.00125, 'Adj. High': 1565.6075, 'Adj. Low': 1502.78125, 'Adj. Close': 1555.23, 'Adj. Volume': 5309783.5}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9v3Jo6MwpfET",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 787
        },
        "outputId": "2f5d9e28-148b-487a-de49-450e9a46898e"
      },
      "source": [
        "train"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Ex-Dividend</th>\n",
              "      <th>Split Ratio</th>\n",
              "      <th>Adj. Open</th>\n",
              "      <th>Adj. High</th>\n",
              "      <th>Adj. Low</th>\n",
              "      <th>Adj. Close</th>\n",
              "      <th>Adj. Volume</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2018-02-22</th>\n",
              "      <td>1502.54</td>\n",
              "      <td>1475.76</td>\n",
              "      <td>1484.76</td>\n",
              "      <td>4732555.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1495.36</td>\n",
              "      <td>1502.54</td>\n",
              "      <td>1475.76</td>\n",
              "      <td>1484.76</td>\n",
              "      <td>4732555.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-02-23</th>\n",
              "      <td>1500.00</td>\n",
              "      <td>1486.50</td>\n",
              "      <td>1500.00</td>\n",
              "      <td>4327008.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1495.34</td>\n",
              "      <td>1500.00</td>\n",
              "      <td>1486.50</td>\n",
              "      <td>1500.00</td>\n",
              "      <td>4327008.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-02-26</th>\n",
              "      <td>1522.84</td>\n",
              "      <td>1507.00</td>\n",
              "      <td>1521.95</td>\n",
              "      <td>4909053.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1509.20</td>\n",
              "      <td>1522.84</td>\n",
              "      <td>1507.00</td>\n",
              "      <td>1521.95</td>\n",
              "      <td>4909053.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-02-27</th>\n",
              "      <td>1526.78</td>\n",
              "      <td>1507.21</td>\n",
              "      <td>1511.98</td>\n",
              "      <td>4708378.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1524.50</td>\n",
              "      <td>1526.78</td>\n",
              "      <td>1507.21</td>\n",
              "      <td>1511.98</td>\n",
              "      <td>4708378.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-02-28</th>\n",
              "      <td>1528.70</td>\n",
              "      <td>1512.00</td>\n",
              "      <td>1512.45</td>\n",
              "      <td>4426580.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1519.51</td>\n",
              "      <td>1528.70</td>\n",
              "      <td>1512.00</td>\n",
              "      <td>1512.45</td>\n",
              "      <td>4426580.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-03-01</th>\n",
              "      <td>1518.49</td>\n",
              "      <td>1465.00</td>\n",
              "      <td>1493.45</td>\n",
              "      <td>6835230.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1513.60</td>\n",
              "      <td>1518.49</td>\n",
              "      <td>1465.00</td>\n",
              "      <td>1493.45</td>\n",
              "      <td>6835230.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-03-02</th>\n",
              "      <td>1501.05</td>\n",
              "      <td>1455.01</td>\n",
              "      <td>1500.25</td>\n",
              "      <td>6587564.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1469.10</td>\n",
              "      <td>1501.05</td>\n",
              "      <td>1455.01</td>\n",
              "      <td>1500.25</td>\n",
              "      <td>6587564.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-03-05</th>\n",
              "      <td>1525.38</td>\n",
              "      <td>1481.00</td>\n",
              "      <td>1523.61</td>\n",
              "      <td>5233934.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1494.24</td>\n",
              "      <td>1525.38</td>\n",
              "      <td>1481.00</td>\n",
              "      <td>1523.61</td>\n",
              "      <td>5233934.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-03-06</th>\n",
              "      <td>1542.13</td>\n",
              "      <td>1528.00</td>\n",
              "      <td>1537.64</td>\n",
              "      <td>4561718.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1533.20</td>\n",
              "      <td>1542.13</td>\n",
              "      <td>1528.00</td>\n",
              "      <td>1537.64</td>\n",
              "      <td>4561718.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-03-07</th>\n",
              "      <td>1545.90</td>\n",
              "      <td>1522.51</td>\n",
              "      <td>1545.00</td>\n",
              "      <td>4174123.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1526.52</td>\n",
              "      <td>1545.90</td>\n",
              "      <td>1522.51</td>\n",
              "      <td>1545.00</td>\n",
              "      <td>4174123.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-03-08</th>\n",
              "      <td>1554.88</td>\n",
              "      <td>1545.25</td>\n",
              "      <td>1551.86</td>\n",
              "      <td>3512528.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1550.00</td>\n",
              "      <td>1554.88</td>\n",
              "      <td>1545.25</td>\n",
              "      <td>1551.86</td>\n",
              "      <td>3512528.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-03-09</th>\n",
              "      <td>1578.94</td>\n",
              "      <td>1559.08</td>\n",
              "      <td>1578.89</td>\n",
              "      <td>4417059.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1563.50</td>\n",
              "      <td>1578.94</td>\n",
              "      <td>1559.08</td>\n",
              "      <td>1578.89</td>\n",
              "      <td>4417059.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-03-12</th>\n",
              "      <td>1605.33</td>\n",
              "      <td>1586.70</td>\n",
              "      <td>1598.39</td>\n",
              "      <td>5115886.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1592.60</td>\n",
              "      <td>1605.33</td>\n",
              "      <td>1586.70</td>\n",
              "      <td>1598.39</td>\n",
              "      <td>5115886.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-03-13</th>\n",
              "      <td>1617.54</td>\n",
              "      <td>1578.01</td>\n",
              "      <td>1588.18</td>\n",
              "      <td>6427066.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1615.96</td>\n",
              "      <td>1617.54</td>\n",
              "      <td>1578.01</td>\n",
              "      <td>1588.18</td>\n",
              "      <td>6427066.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-03-14</th>\n",
              "      <td>1606.44</td>\n",
              "      <td>1590.89</td>\n",
              "      <td>1591.00</td>\n",
              "      <td>4164395.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1597.00</td>\n",
              "      <td>1606.44</td>\n",
              "      <td>1590.89</td>\n",
              "      <td>1591.00</td>\n",
              "      <td>4164395.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-03-15</th>\n",
              "      <td>1596.91</td>\n",
              "      <td>1578.11</td>\n",
              "      <td>1582.32</td>\n",
              "      <td>4026744.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1595.00</td>\n",
              "      <td>1596.91</td>\n",
              "      <td>1578.11</td>\n",
              "      <td>1582.32</td>\n",
              "      <td>4026744.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-03-16</th>\n",
              "      <td>1589.44</td>\n",
              "      <td>1567.50</td>\n",
              "      <td>1571.68</td>\n",
              "      <td>5145054.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1583.45</td>\n",
              "      <td>1589.44</td>\n",
              "      <td>1567.50</td>\n",
              "      <td>1571.68</td>\n",
              "      <td>5145054.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-03-19</th>\n",
              "      <td>1561.66</td>\n",
              "      <td>1525.35</td>\n",
              "      <td>1544.93</td>\n",
              "      <td>6376619.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1554.53</td>\n",
              "      <td>1561.66</td>\n",
              "      <td>1525.35</td>\n",
              "      <td>1544.93</td>\n",
              "      <td>6376619.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-03-20</th>\n",
              "      <td>1587.00</td>\n",
              "      <td>1545.41</td>\n",
              "      <td>1586.51</td>\n",
              "      <td>4507049.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1550.34</td>\n",
              "      <td>1587.00</td>\n",
              "      <td>1545.41</td>\n",
              "      <td>1586.51</td>\n",
              "      <td>4507049.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-03-21</th>\n",
              "      <td>1590.00</td>\n",
              "      <td>1563.17</td>\n",
              "      <td>1581.86</td>\n",
              "      <td>4667291.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1586.45</td>\n",
              "      <td>1590.00</td>\n",
              "      <td>1563.17</td>\n",
              "      <td>1581.86</td>\n",
              "      <td>4667291.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-03-22</th>\n",
              "      <td>1573.85</td>\n",
              "      <td>1542.40</td>\n",
              "      <td>1544.10</td>\n",
              "      <td>6177737.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1565.47</td>\n",
              "      <td>1573.85</td>\n",
              "      <td>1542.40</td>\n",
              "      <td>1544.10</td>\n",
              "      <td>6177737.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-03-23</th>\n",
              "      <td>1549.02</td>\n",
              "      <td>1495.36</td>\n",
              "      <td>1495.56</td>\n",
              "      <td>7843966.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1539.01</td>\n",
              "      <td>1549.02</td>\n",
              "      <td>1495.36</td>\n",
              "      <td>1495.56</td>\n",
              "      <td>7843966.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-03-26</th>\n",
              "      <td>1556.99</td>\n",
              "      <td>1499.25</td>\n",
              "      <td>1555.86</td>\n",
              "      <td>5547618.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1530.00</td>\n",
              "      <td>1556.99</td>\n",
              "      <td>1499.25</td>\n",
              "      <td>1555.86</td>\n",
              "      <td>5547618.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-03-27</th>\n",
              "      <td>1575.96</td>\n",
              "      <td>1482.32</td>\n",
              "      <td>1497.05</td>\n",
              "      <td>6793279.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1572.40</td>\n",
              "      <td>1575.96</td>\n",
              "      <td>1482.32</td>\n",
              "      <td>1497.05</td>\n",
              "      <td>6793279.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               High      Low    Close  ...  Adj. Low  Adj. Close  Adj. Volume\n",
              "Date                                   ...                                   \n",
              "2018-02-22  1502.54  1475.76  1484.76  ...   1475.76     1484.76    4732555.0\n",
              "2018-02-23  1500.00  1486.50  1500.00  ...   1486.50     1500.00    4327008.0\n",
              "2018-02-26  1522.84  1507.00  1521.95  ...   1507.00     1521.95    4909053.0\n",
              "2018-02-27  1526.78  1507.21  1511.98  ...   1507.21     1511.98    4708378.0\n",
              "2018-02-28  1528.70  1512.00  1512.45  ...   1512.00     1512.45    4426580.0\n",
              "2018-03-01  1518.49  1465.00  1493.45  ...   1465.00     1493.45    6835230.0\n",
              "2018-03-02  1501.05  1455.01  1500.25  ...   1455.01     1500.25    6587564.0\n",
              "2018-03-05  1525.38  1481.00  1523.61  ...   1481.00     1523.61    5233934.0\n",
              "2018-03-06  1542.13  1528.00  1537.64  ...   1528.00     1537.64    4561718.0\n",
              "2018-03-07  1545.90  1522.51  1545.00  ...   1522.51     1545.00    4174123.0\n",
              "2018-03-08  1554.88  1545.25  1551.86  ...   1545.25     1551.86    3512528.0\n",
              "2018-03-09  1578.94  1559.08  1578.89  ...   1559.08     1578.89    4417059.0\n",
              "2018-03-12  1605.33  1586.70  1598.39  ...   1586.70     1598.39    5115886.0\n",
              "2018-03-13  1617.54  1578.01  1588.18  ...   1578.01     1588.18    6427066.0\n",
              "2018-03-14  1606.44  1590.89  1591.00  ...   1590.89     1591.00    4164395.0\n",
              "2018-03-15  1596.91  1578.11  1582.32  ...   1578.11     1582.32    4026744.0\n",
              "2018-03-16  1589.44  1567.50  1571.68  ...   1567.50     1571.68    5145054.0\n",
              "2018-03-19  1561.66  1525.35  1544.93  ...   1525.35     1544.93    6376619.0\n",
              "2018-03-20  1587.00  1545.41  1586.51  ...   1545.41     1586.51    4507049.0\n",
              "2018-03-21  1590.00  1563.17  1581.86  ...   1563.17     1581.86    4667291.0\n",
              "2018-03-22  1573.85  1542.40  1544.10  ...   1542.40     1544.10    6177737.0\n",
              "2018-03-23  1549.02  1495.36  1495.56  ...   1495.36     1495.56    7843966.0\n",
              "2018-03-26  1556.99  1499.25  1555.86  ...   1499.25     1555.86    5547618.0\n",
              "2018-03-27  1575.96  1482.32  1497.05  ...   1482.32     1497.05    6793279.0\n",
              "\n",
              "[24 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UED6_06NpNtI",
        "colab_type": "code",
        "outputId": "9e604795-c59c-473c-ec48-68e3e69a12a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "print('Predictions Using Linear Regression')\n",
        "print('===================================')\n",
        "for i in train:\n",
        "  test=train[i]\n",
        "  x_train,x_test,y_train,y_test=train_test_split(train,test,test_size=0.3)\n",
        "  model=LinearRegression()\n",
        "  model.fit(x_train,y_train)\n",
        "  predi=model.predict(x_test)\n",
        "  acc=model.score(x_test,y_test)\n",
        "  predict=mean(predi)\n",
        "  print(predict)\n",
        "  print('Accuracy is:',acc)\n",
        "  dict.update({i:predict})\n",
        "print(dict)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predictions Using Linear Regression\n",
            "===================================\n",
            "1543.6899999999998\n",
            "Accuracy is: 1.0\n",
            "1570.2525000000608\n",
            "Accuracy is: 1.0\n",
            "1495.9025000000001\n",
            "Accuracy is: 1.0\n",
            "1539.7925\n",
            "Accuracy is: 1.0\n",
            "5229642.125000001\n",
            "Accuracy is: 1.0\n",
            "{'Adj. Open': 1543.6899999999998, 'Adj. High': 1570.2525000000608, 'Adj. Low': 1495.9025000000001, 'Adj. Close': 1539.7925, 'Adj. Volume': 5229642.125000001}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsCZtO5gMC-q",
        "colab_type": "code",
        "outputId": "6f2fa5cf-a22f-46d9-cccc-de60bb7b9ac5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        }
      },
      "source": [
        "print('Predictions Using RandomForestRegressor')\n",
        "print('===================================')\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "for i in train:\n",
        "  test=train[i]\n",
        "  x_train,x_test,y_train,y_test=train_test_split(train,test,test_size=0.3)\n",
        "  model=RandomForestRegressor()\n",
        "  model.fit(x_train,y_train)\n",
        "  predi=model.predict(x_test)\n",
        "  acc=model.score(x_test,y_test)\n",
        "  predict=mean(predi)\n",
        "  print(predict)\n",
        "  print('Accuracy is:',acc)\n",
        "  dict.update({i:predict})\n",
        "print('====================================')\n",
        "print(dict)\n",
        "print('====================================')"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predictions Using RandomForestRegressor\n",
            "===================================\n",
            "1545.3872500000002\n",
            "Accuracy is: 0.9237849981618416\n",
            "1556.0313750000003\n",
            "Accuracy is: 0.9453259617779682\n",
            "1535.592875\n",
            "Accuracy is: 0.9294788554337958\n",
            "1533.54375\n",
            "Accuracy is: 0.9389752077371253\n",
            "5310482.0\n",
            "Accuracy is: 0.9700285989362292\n",
            "====================================\n",
            "{'Adj. Open': 1545.3872500000002, 'Adj. High': 1556.0313750000003, 'Adj. Low': 1535.592875, 'Adj. Close': 1533.54375, 'Adj. Volume': 5310482.0}\n",
            "====================================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trv4taxnr9Vf",
        "colab_type": "code",
        "outputId": "0cff61d8-827c-48d5-ed38-30377436c46f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "print('Ridge Regression')\n",
        "print('================')\n",
        "from sklearn import linear_model\n",
        "for i in train:\n",
        "  test=train[i]\n",
        "  x_train,x_test,y_train,y_test=train_test_split(train,test,test_size=0.3)\n",
        "  model=reg=linear_model.Ridge(alpha=0.5)\n",
        "  model.fit(x_train,y_train)\n",
        "  predi=model.predict(x_test)\n",
        "  acc=model.score(x_test,y_test)\n",
        "  predict=mean(predi)\n",
        "  print(predict)\n",
        "  print('Accuracy is:',acc)\n",
        "  dict.update({i:predict})\n",
        "print('====================================')\n",
        "print(dict)\n",
        "print('====================================')\n"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ridge Regression\n",
            "================\n",
            "1543.2699875085468\n",
            "Accuracy is: 0.9999999758238046\n",
            "1547.120761080392\n",
            "Accuracy is: 0.9999992498659825\n",
            "1529.2350792887833\n",
            "Accuracy is: 0.999999993057789\n",
            "1529.7057851905058\n",
            "Accuracy is: 0.9999999716508814\n",
            "4991961.999999991\n",
            "Accuracy is: 1.0\n",
            "====================================\n",
            "{'Adj. Open': 1543.2699875085468, 'Adj. High': 1547.120761080392, 'Adj. Low': 1529.2350792887833, 'Adj. Close': 1529.7057851905058, 'Adj. Volume': 4991961.999999991}\n",
            "====================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0O7TJhot_z6X",
        "colab_type": "code",
        "outputId": "37d52763-79ab-47fa-e5dc-1475c4c26f49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "print('Huber Regression for prediction')\n",
        "print('===============================')\n",
        "from sklearn.linear_model import HuberRegressor\n",
        "for i in train:\n",
        "  test=train[i]\n",
        "  x_train,x_test,y_train,y_test=train_test_split(train,test,test_size=0.3)\n",
        "  model=HuberRegressor()\n",
        "  model.fit(x_train,y_train)\n",
        "  predi=model.predict(x_test)\n",
        "  acc=model.score(x_test,y_test)\n",
        "  predict=mean(predi)\n",
        "  print(predict)\n",
        "  print('Accuracy is:',acc)\n",
        "  dict.update({i:predict})\n",
        "print('====================================')\n",
        "print(dict)\n",
        "print('====================================')"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Huber Regression for prediction\n",
            "===============================\n",
            "1522.71853923884\n",
            "Accuracy is: 0.9071695582481262\n",
            "1559.1513329968866\n",
            "Accuracy is: 0.9825495760282813\n",
            "1529.183937481484\n",
            "Accuracy is: 0.9431310507164435\n",
            "1545.5836050229686\n",
            "Accuracy is: 0.857884654581026\n",
            "5094683.999886718\n",
            "Accuracy is: 1.0\n",
            "====================================\n",
            "{'Adj. Open': 1522.71853923884, 'Adj. High': 1559.1513329968866, 'Adj. Low': 1529.183937481484, 'Adj. Close': 1545.5836050229686, 'Adj. Volume': 5094683.999886718}\n",
            "====================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRFe02t_QEGT",
        "colab_type": "code",
        "outputId": "f98e618a-d8a2-4938-e4b2-c451b7bd1170",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "print('Gradient Boost Regression for prediction')\n",
        "print('===============================')\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "for i in train:\n",
        "  test=train[i]\n",
        "  x_train,x_test,y_train,y_test=train_test_split(train,test,test_size=0.3)\n",
        "  model=GradientBoostingRegressor()\n",
        "  model.fit(x_train,y_train)\n",
        "  predi=model.predict(x_test)\n",
        "  acc=model.score(x_test,y_test)\n",
        "  predict=mean(predi)\n",
        "  print(predict)\n",
        "  print('Accuracy is:',acc)\n",
        "  dict.update({i:predict})\n",
        "print('====================================')\n",
        "print(dict)\n",
        "print('====================================')"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Gradient Boost Regression for prediction\n",
            "===============================\n",
            "1550.7913164523236\n",
            "Accuracy is: 0.9215627021252272\n",
            "1541.2623425223944\n",
            "Accuracy is: 0.8754610760882885\n",
            "1528.7444241462936\n",
            "Accuracy is: 0.8949112402592779\n",
            "1564.8636182636785\n",
            "Accuracy is: 0.7066701898144161\n",
            "4890066.318475818\n",
            "Accuracy is: 0.959855320796391\n",
            "====================================\n",
            "{'Adj. Open': 1550.7913164523236, 'Adj. High': 1541.2623425223944, 'Adj. Low': 1528.7444241462936, 'Adj. Close': 1564.8636182636785, 'Adj. Volume': 4890066.318475818}\n",
            "====================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uz4QyIZlQ9Ls",
        "colab_type": "code",
        "outputId": "752e1db4-7f35-4aa1-aab6-c3d7b224816d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        }
      },
      "source": [
        "print('Support Vector Regressor for prediction')\n",
        "print('===============================')\n",
        "from sklearn.svm import SVR\n",
        "for i in train:\n",
        "  test=train[i]\n",
        "  x_train,x_test,y_train,y_test=train_test_split(train,test,test_size=0.3)\n",
        "  model=SVR()\n",
        "  model.fit(x_train,y_train)\n",
        "  predi=model.predict(x_test)\n",
        "  acc=model.score(x_test,y_test)\n",
        "  predict=mean(predi)\n",
        "  print(predict)\n",
        "  print('Accuracy is:',acc)\n",
        "  dict.update({i:predict})\n",
        "print('====================================')\n",
        "print(dict)\n",
        "print('====================================')"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Support Vector Regressor for prediction\n",
            "===============================\n",
            "1546.77\n",
            "Accuracy is: -0.005825962775652949\n",
            "1545.575\n",
            "Accuracy is: -0.5059390377888444\n",
            "1517.255\n",
            "Accuracy is: -0.030742030094457858\n",
            "1544.5149999999999\n",
            "Accuracy is: -0.003970138659983968\n",
            "4720466.5\n",
            "Accuracy is: -0.5293969939513017\n",
            "====================================\n",
            "{'Adj. Open': 1546.77, 'Adj. High': 1545.575, 'Adj. Low': 1517.255, 'Adj. Close': 1544.5149999999999, 'Adj. Volume': 4720466.5}\n",
            "====================================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLq7tgK_SR_l",
        "colab_type": "code",
        "outputId": "7dcdaead-632e-46dc-8f79-1d1742b200a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "print('KN Regressor for prediction')\n",
        "print('===============================')\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "for i in train:\n",
        "  test=train[i]\n",
        "  x_train,x_test,y_train,y_test=train_test_split(train,test,test_size=0.3)\n",
        "  model=KNeighborsRegressor()\n",
        "  model.fit(x_train,y_train)\n",
        "  predi=model.predict(x_test)\n",
        "  acc=model.score(x_test,y_test)\n",
        "  predict=mean(predi)\n",
        "  print(predict)\n",
        "  print('Accuracy is:',acc)\n",
        "  dict.update({i:predict})\n",
        "print('====================================')\n",
        "print(dict)\n",
        "print('====================================')"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "KN Regressor for prediction\n",
            "===============================\n",
            "1537.8715\n",
            "Accuracy is: -0.34173350743444497\n",
            "1564.8375\n",
            "Accuracy is: -1.2529359872040653\n",
            "1535.37525\n",
            "Accuracy is: -0.12943258467245977\n",
            "1519.319\n",
            "Accuracy is: -2.661252879593229\n",
            "4763907.575\n",
            "Accuracy is: 0.8706858452945156\n",
            "====================================\n",
            "{'Adj. Open': 1537.8715, 'Adj. High': 1564.8375, 'Adj. Low': 1535.37525, 'Adj. Close': 1519.319, 'Adj. Volume': 4763907.575}\n",
            "====================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKP2seJI6k4z",
        "colab_type": "code",
        "outputId": "a98c32fd-fb5f-4fc6-d416-b8ccdf775d08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "print(dict)\n",
        "from prettytable import PrettyTable \n",
        "Models = PrettyTable(['Model', 'Accuracy'])\n",
        "for key, val in dict.items():\n",
        "   Models.add_row([key, val])\n",
        "print (Models)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'DecisionTreeRegression': 0.8040100178100021, 'Linear Regression': 1.0, 'RF Regression': 0.9621878545661656, 'Ridge Regression': 0.9999999957069496, 'BaysianRidge Regression': 0.9997937396570692, 'Huber Regression': 0.8357038552592808, 'GBR Regression': 0.9539417959529588, 'SVR Regression': -0.04381329088698971, 'KNR Regression': -0.5032764844656126}\n",
            "+-------------------------+----------------------+\n",
            "|          Model          |       Accuracy       |\n",
            "+-------------------------+----------------------+\n",
            "|  DecisionTreeRegression |  0.8040100178100021  |\n",
            "|    Linear Regression    |         1.0          |\n",
            "|      RF Regression      |  0.9621878545661656  |\n",
            "|     Ridge Regression    |  0.9999999957069496  |\n",
            "| BaysianRidge Regression |  0.9997937396570692  |\n",
            "|     Huber Regression    |  0.8357038552592808  |\n",
            "|      GBR Regression     |  0.9539417959529588  |\n",
            "|      SVR Regression     | -0.04381329088698971 |\n",
            "|      KNR Regression     | -0.5032764844656126  |\n",
            "+-------------------------+----------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}